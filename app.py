import streamlit as st
import pandas as pd
import math
import io
import os
import re
import shutil
import tempfile
import subprocess
import gc
import requests
from datetime import timedelta, datetime, date
from itertools import groupby
from copy import copy

import openpyxl
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment
from openpyxl.drawing.image import Image as XLImage
from openpyxl.drawing.spreadsheet_drawing import OneCellAnchor, AnchorMarker, XDRPositiveSize2D

# =========================================================
# 0. Streamlit Page
# =========================================================
st.set_page_config(layout="wide", page_title="Cue Sheet Pro (Bæ–¹æ¡ˆ-æ¨£æ¿å¥—ç”¨)")

# =========================================================
# 1. Global Constants
# =========================================================
GSHEET_SHARE_URL = "https://docs.google.com/spreadsheets/d/1bzmG-N8XFsj8m3LUPqA8K70AcIqaK4Qhq1VPWcK0w_s/edit?usp=sharing"

# å¦‚æœä½ æ¨£æ¿å…§å·²ç¶“æœ‰ Logoï¼ˆå¼·çƒˆå»ºè­°ï¼‰ï¼Œå°±ä¸ä¸€å®šè¦ç”¨ URL ä¸‹è¼‰
BOLIN_LOGO_URL = "https://docs.google.com/drawings/d/17Uqgp-7LJJj9E4bV7Azo7TwXESPKTTIsmTbf-9tU9eE/export/png"

FONT_MAIN = "å¾®è»Ÿæ­£é»‘é«”"

REGIONS_ORDER = ["åŒ—å€", "æ¡ƒç«¹è‹—", "ä¸­å€", "é›²å˜‰å—", "é«˜å±", "æ±å€"]
DURATIONS = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]

REGION_DISPLAY_MAP = {
    "åŒ—å€": "åŒ—å€-åŒ—åŒ—åŸº",
    "æ¡ƒç«¹è‹—": "æ¡ƒå€-æ¡ƒç«¹è‹—",
    "ä¸­å€": "ä¸­å€-ä¸­å½°æŠ•",
    "é›²å˜‰å—": "é›²å˜‰å—å€-é›²å˜‰å—",
    "é«˜å±": "é«˜å±å€-é«˜å±",
    "æ±å€": "æ±å€-å®œèŠ±æ±",
    "å…¨çœé‡è²©": "å…¨çœé‡è²©",
    "å…¨çœè¶…å¸‚": "å…¨çœè¶…å¸‚"
}

MEDIA_ORDER = {"å…¨å®¶å»£æ’­": 1, "æ–°é®®è¦–": 2, "å®¶æ¨‚ç¦": 3}

TEMPLATE_PATHS = {
    "Dongwu": os.path.join("templates", "æ±å³æ¨£æ¿.xlsx"),
    "Shenghuo": os.path.join("templates", "ç”Ÿæ´»æ¨£æ¿.xlsx"),
    "Bolin": os.path.join("templates", "é‰‘éœ–æ¨£æ¿.xlsx"),
}

# =========================================================
# 2. Small Helpers
# =========================================================
def safe_filename(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', "_", name).strip()

def region_display(region: str) -> str:
    return REGION_DISPLAY_MAP.get(region, region)

def parse_gsheet_id(url: str):
    m = re.search(r"/d/([a-zA-Z0-9-_]+)", url)
    return m.group(1) if m else None

def col_width_to_pixels(excel_width: float) -> int:
    """
    è¿‘ä¼¼æ›ç®—ï¼šExcel column width -> pixels
    å¸¸è¦‹å…¬å¼ï¼špx â‰ˆ width*7 + 5
    """
    if excel_width is None:
        return 64
    return int(excel_width * 7 + 5)

def px_to_emu(px: int) -> int:
    # 1 px at 96 dpi = 9525 EMU
    return int(px * 9525)

def find_soffice_path():
    soffice = shutil.which("soffice") or shutil.which("libreoffice")
    if soffice:
        return soffice
    if os.name == "nt":
        candidates = [
            r"C:\Program Files\LibreOffice\program\soffice.exe",
            r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        ]
        for p in candidates:
            if os.path.exists(p):
                return p
    return None

@st.cache_data(show_spinner="æ­£åœ¨ä¸‹è¼‰ Logo...", ttl=3600)
def fetch_logo_bytes(url: str):
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            return r.content
    except:
        pass
    return None

@st.cache_data(show_spinner="æ­£åœ¨ç”Ÿæˆ PDF (LibreOffice)...", ttl=3600)
def xlsx_bytes_to_pdf_bytes(xlsx_bytes: bytes):
    soffice = find_soffice_path()
    if not soffice:
        return None, "Fail", "æ‰¾ä¸åˆ° LibreOffice (soffice)ã€‚é›²ç«¯è«‹ç”¨ packages.txt å®‰è£ libreofficeã€‚"
    try:
        with tempfile.TemporaryDirectory() as tmp:
            xlsx_path = os.path.join(tmp, "cue.xlsx")
            with open(xlsx_path, "wb") as f:
                f.write(xlsx_bytes)

            # pdf:calc_pdf_Export æ¯”è¼ƒç©©
            subprocess.run(
                [soffice, "--headless", "--nologo", "--convert-to", "pdf:calc_pdf_Export", "--outdir", tmp, xlsx_path],
                capture_output=True,
                timeout=90,
            )

            pdf_path = os.path.join(tmp, "cue.pdf")
            if not os.path.exists(pdf_path):
                # LibreOffice æœ‰æ™‚å€™æœƒç”¨åŸæª”åè¼¸å‡º
                for fn in os.listdir(tmp):
                    if fn.lower().endswith(".pdf"):
                        pdf_path = os.path.join(tmp, fn)
                        break

            if os.path.exists(pdf_path):
                with open(pdf_path, "rb") as f:
                    return f.read(), "LibreOffice", ""
            return None, "Fail", "LibreOffice æœªç”¢å‡º PDF"
    except subprocess.TimeoutExpired:
        return None, "Fail", "è½‰æª”é€¾æ™‚"
    except Exception as e:
        return None, "Fail", str(e)
    finally:
        gc.collect()

# =========================================================
# 3. Load Config from Google Sheet
# =========================================================
@st.cache_data(ttl=300)
def load_config_from_cloud(share_url):
    file_id = parse_gsheet_id(share_url)
    if not file_id:
        return None, None, None, None, "GSHEET é€£çµæ ¼å¼éŒ¯èª¤"

    def read_sheet(sheet_name):
        url = f"https://docs.google.com/spreadsheets/d/{file_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
        return pd.read_csv(url)

    try:
        df_store = read_sheet("Stores")
        df_store.columns = [c.strip() for c in df_store.columns]
        store_counts = dict(zip(df_store["Key"], df_store["Display_Name"]))
        store_counts_num = dict(zip(df_store["Key"], df_store["Count"]))

        df_fact = read_sheet("Factors")
        df_fact.columns = [c.strip() for c in df_fact.columns]
        sec_factors = {}
        for _, row in df_fact.iterrows():
            m = row["Media"]
            sec_factors.setdefault(m, {})
            sec_factors[m][int(row["Seconds"])] = float(row["Factor"])
        # alias
        name_map = {"å…¨å®¶æ–°é®®è¦–": "æ–°é®®è¦–", "å…¨å®¶å»£æ’­": "å…¨å®¶å»£æ’­", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"}
        for k, v in name_map.items():
            if k in sec_factors and v not in sec_factors:
                sec_factors[v] = sec_factors[k]

        df_price = read_sheet("Pricing")
        df_price.columns = [c.strip() for c in df_price.columns]
        pricing_db = {}
        for _, row in df_price.iterrows():
            m = row["Media"]
            r = row["Region"]
            if m == "å®¶æ¨‚ç¦":
                pricing_db.setdefault(m, {})
                pricing_db[m][r] = {
                    "List": int(row["List_Price"]),
                    "Net": int(row["Net_Price"]),
                    "Std_Spots": int(row["Std_Spots"]),
                    "Day_Part": row["Day_Part"],
                }
            else:
                pricing_db.setdefault(m, {"Std_Spots": int(row["Std_Spots"]), "Day_Part": row["Day_Part"]})
                pricing_db[m][r] = [int(row["List_Price"]), int(row["Net_Price"])]

        return store_counts, store_counts_num, pricing_db, sec_factors, None
    except Exception as e:
        return None, None, None, None, f"è®€å–å¤±æ•—: {str(e)}"

def get_sec_factor(media_type, seconds, sec_factors):
    factors = sec_factors.get(media_type)
    if not factors:
        return 1.0
    if seconds in factors:
        return factors[seconds]
    # fallback: linear scaling
    for base in [10, 20, 15, 30]:
        if base in factors:
            return (seconds / base) * factors[base]
    return 1.0

def calculate_schedule(total_spots, days):
    if days <= 0:
        return []
    # å¼·åˆ¶å¶æ•¸
    if total_spots % 2 != 0:
        total_spots += 1
    half = total_spots // 2
    base, rem = divmod(half, days)
    sch = [base + (1 if i < rem else 0) for i in range(days)]
    return [x * 2 for x in sch]

def get_remarks_text(sign_deadline, billing_month, payment_date):
    d_str = sign_deadline.strftime("%Y/%m/%d (%a)") if sign_deadline else "____/__/__ (__)"
    p_str = payment_date.strftime("%Y/%m/%d") if payment_date else "____/__/__"
    return [
        f"1.è«‹æ–¼ {d_str} 11:30å‰ å›ç°½åŠé€²å–®ï¼Œæ–¹å¯é †åˆ©ä¸Šæª”ã€‚",
        "2.ä»¥ä¸Šç¯€ç›®åç¨±å¦‚æœ‰ç•°å‹•ï¼Œä»¥ä¸Šæª”æ™‚ç¯€ç›®åç¨±ç‚ºä¸»ï¼Œå¦‚é‡æ™‚æ®µæ»¿æª”ï¼Œä¸Šæª”æ™‚é–“æŒªå¾Œæˆ–æ›´æ›è‡³åŒç´šæ™‚æ®µã€‚",
        "3.é€šè·¯åº—é‹ªæ•¸èˆ‡é–‹æ©Ÿç‡è‡³å°‘ä¸ƒæˆ(ä»¥ä¸Š)ã€‚æ¯æ—¥å› åŠ ç›Ÿæ•¸èª¿æ•´ï¼Œæˆ–é‡åº—èˆ–å¹´åº¦å­£åº¦æ”¹è£ã€è¨­å‚™ç¶­è­·å‡ç´šåŠä¿ä¿®ç­‰ç‹€æ³ï¼Œæœƒæœ‰ä¸€å®šå¹…åº¦å¢æ¸›ã€‚",
        "4.è¨—æ’­æ–¹éœ€æ–¼ä¸Šæª”å‰ 5 å€‹å·¥ä½œå¤©ï¼Œæä¾›å»£å‘Šå¸¶(mp3)ã€å½±ç‰‡/å½±åƒ 1920x1080 (mp4)ã€‚",
        f"5.é›™æ–¹åŒæ„è²»ç”¨è«‹æ¬¾æœˆä»½ : {billing_month}ï¼Œå¦‚æœ‰ä¿®æ­£å¿…è¦ï¼Œå°‡å¦è¡ŒE-Mailå‘ŠçŸ¥ï¼Œä¸¦è¦–ç‚ºæ­£å¼åˆç´„ä¹‹ä¸€éƒ¨åˆ†ã€‚",
        f"6.ä»˜æ¬¾å…Œç¾æ—¥æœŸï¼š{p_str}",
    ]

# =========================================================
# 4. Core Calculation (å«ä½ èªªçš„å…¨çœ/åˆ†å€ + 1.1 è¦å‰‡)
# =========================================================
def calculate_plan_data(config, total_budget, days_count, pricing_db, sec_factors, store_counts_num):
    """
    ç”¢å‡º rowsï¼š
      - rate_display: é¡¯ç¤ºç”¨ï¼ˆä½ è¦æ±‚ rate(Net) é¡¯ç¤ºã€è©²åˆ†å€ç¸½åƒ¹ã€ï¼Œä¸æ˜¯å–®æª”ï¼‰
      - pkg_display:  éå…¨çœï¼šåˆ†å€ç¸½åƒ¹ï¼ˆè‹¥æœªé”æ¨™ *1.1ï¼‰
                     å…¨çœï¼šåˆ†å€é¡¯ç¤ºåŸåƒ¹(ä¸*1.1)ï¼Œä½† nat_pkg_displayï¼ˆpackage-costï¼‰è¦ *1.1ï¼ˆè‹¥æœªé”æ¨™ï¼‰
      - nat_pkg_display: å…¨çœæ‰“åŒ…åƒ¹ï¼ˆåˆä½µæ ¼é¡¯ç¤ºï¼‰
      - is_pkg_member: æ˜¯å¦å±¬æ–¼å…¨çœåˆä½µ package-cost çš„ç¾¤çµ„
    """
    rows = []
    total_list_accum = 0

    for m, cfg in config.items():
        m_budget_total = total_budget * (cfg["share"] / 100.0)

        for sec, sec_pct in cfg["sec_shares"].items():
            s_budget = m_budget_total * (sec_pct / 100.0)
            if s_budget <= 0:
                continue

            factor = get_sec_factor(m, sec, sec_factors)

            if m in ["å…¨å®¶å»£æ’­", "æ–°é®®è¦–"]:
                db = pricing_db[m]
                std_spots = db["Std_Spots"]
                daypart = db["Day_Part"]

                # è¨ˆç®—ç”¨å€åŸŸï¼šå…¨çœ=>ç”¨å…¨çœï¼›åˆ†å€=>ç”¨é¸åˆ°çš„åˆ†å€
                is_nat = cfg["is_national"]
                calc_regs = ["å…¨çœ"] if is_nat else cfg["regions"]
                display_regs = REGIONS_ORDER if is_nat else cfg["regions"]

                # --- Net ç”¨ä¾†æ±ºå®š spotsï¼ˆå«æœªé”æ¨™æ™‚æˆæœ¬ *1.1ï¼‰---
                unit_net_sum = 0.0
                for r in calc_regs:
                    unit_net_sum += (db[r][1] / std_spots) * factor

                if unit_net_sum <= 0:
                    continue

                spots_init = math.ceil(s_budget / unit_net_sum)
                is_under_target = spots_init < std_spots
                calc_penalty = 1.1 if is_under_target else 1.0

                spots_final = math.ceil(s_budget / (unit_net_sum * calc_penalty))
                if spots_final % 2 != 0:
                    spots_final += 1
                if spots_final <= 0:
                    spots_final = 2

                sch = calculate_schedule(spots_final, days_count)

                # --- é¡¯ç¤ºè¦å‰‡ï¼ˆä½ çš„è¦æ±‚ï¼‰ ---
                # A) æ²’é¸å…¨çœï¼šåˆ†å€åƒ¹èˆ‡åŠ ç¸½éƒ½è¦éµå®ˆæœªé”æ¨™ *1.1
                # B) æœ‰é¸å…¨çœï¼špackage-cost(å…¨çœæ‰“åŒ…åƒ¹) è‹¥æœªé”æ¨™è¦ *1.1
                #              ä½†åˆ†å€é¡¯ç¤ºåƒ¹æ ¼ä¸è¦å† *1.1ï¼ˆé¿å…åƒ¹å·®éå¤§è®“å®¢æˆ¶æ‡·ç–‘ï¼‰
                row_display_penalty = (1.1 if is_under_target else 1.0) if (not is_nat) else 1.0
                nat_pkg_penalty = (1.1 if is_under_target else 1.0) if is_nat else 1.0

                # å…¨çœæ‰“åŒ…åƒ¹ï¼ˆåˆä½µé¡¯ç¤ºï¼‰
                nat_pkg_display = 0
                if is_nat:
                    nat_list = db["å…¨çœ"][0]
                    nat_pkg_display = int((nat_list / std_spots) * factor * nat_pkg_penalty * spots_final)
                    total_list_accum += nat_pkg_display

                for r in display_regs:
                    # åˆ†å€é¡¯ç¤ºç”¨ list totalï¼ˆä¸ä¸€å®šç­‰æ–¼å…¨çœè¨ˆåƒ¹ï¼‰
                    list_price_region = db[r][0]
                    # ä½ è¦ rate(Net) é¡¯ç¤ºã€Œè©²åˆ†å€ç¸½åƒ¹ã€ï¼šæ‰€ä»¥é€™è£¡ç›´æ¥ç®—ç¸½åƒ¹
                    total_rate_display = int((list_price_region / std_spots) * factor * row_display_penalty * spots_final)

                    # package-cost æ¬„ä½ï¼š
                    # - éå…¨çœï¼šå°±é¡¯ç¤ºåˆ†å€ç¸½åƒ¹ï¼ˆåŒ total_rate_displayï¼‰
                    # - å…¨çœï¼šè©²æ¬„ä½ç”± nat_pkg_display åˆä½µé¡¯ç¤ºï¼ˆåˆ†å€å„åˆ—ä¸å¡«ï¼‰
                    pkg_display = total_rate_display

                    # éå…¨çœæ‰æŠŠåˆ†å€åŠ ç¸½åˆ—å…¥ total_list_accumï¼ˆç”¨æ–¼æŠ˜æ‰£ç‡ç­‰ï¼‰
                    if not is_nat:
                        total_list_accum += pkg_display

                    program_num_key = (f"æ–°é®®è¦–_{r}" if m == "æ–°é®®è¦–" else r)
                    rows.append({
                        "media": m,
                        "region": region_display(r),
                        "program_num": int(store_counts_num.get(program_num_key, 0)),
                        "daypart": daypart,
                        "seconds": int(sec),
                        "schedule": sch,
                        "spots": sum(sch),  # å³å´æª”æ¬¡æ¬„é€šå¸¸è¦é¡¯ç¤ºç¸½æª”æ¬¡
                        "rate_display": total_rate_display,  # âœ…ä½ è¦æ±‚ï¼šé¡¯ç¤ºç¸½åƒ¹
                        "pkg_display": pkg_display,
                        "is_pkg_member": is_nat,
                        "nat_pkg_display": nat_pkg_display,
                    })

            elif m == "å®¶æ¨‚ç¦":
                db = pricing_db["å®¶æ¨‚ç¦"]
                base_std = db["é‡è²©_å…¨çœ"]["Std_Spots"]
                daypart_h = db["é‡è²©_å…¨çœ"]["Day_Part"]
                daypart_s = db["è¶…å¸‚_å…¨çœ"]["Day_Part"]

                # ç”¨é‡è²© Net æ¨ spotsï¼ˆä½ çš„åŸé‚è¼¯ï¼‰
                unit_net = (db["é‡è²©_å…¨çœ"]["Net"] / base_std) * factor
                spots_init = math.ceil(s_budget / unit_net)
                penalty = 1.1 if spots_init < base_std else 1.0

                spots_final = math.ceil(s_budget / (unit_net * penalty))
                if spots_final % 2 != 0:
                    spots_final += 1
                if spots_final <= 0:
                    spots_final = 2

                sch_h = calculate_schedule(spots_final, days_count)
                # List é¡¯ç¤ºï¼ˆç¸½åƒ¹ï¼‰
                unit_list_h = (db["é‡è²©_å…¨çœ"]["List"] / base_std) * factor * penalty
                total_rate_h = int(unit_list_h * spots_final)
                total_list_accum += total_rate_h

                rows.append({
                    "media": "å®¶æ¨‚ç¦",
                    "region": "å…¨çœé‡è²©",
                    "program_num": int(store_counts_num.get("å®¶æ¨‚ç¦_é‡è²©", 0)),
                    "daypart": daypart_h,
                    "seconds": int(sec),
                    "schedule": sch_h,
                    "spots": sum(sch_h),
                    "rate_display": total_rate_h,
                    "pkg_display": total_rate_h,
                    "is_pkg_member": False,
                    "nat_pkg_display": 0,
                })

                # è¶…å¸‚ï¼šè¨ˆé‡è²©ï¼ˆä¾ä½ åŸé‚è¼¯ï¼‰
                ratio = db["è¶…å¸‚_å…¨çœ"]["Std_Spots"] / base_std
                spots_s = int(round(spots_final * ratio))
                sch_s = calculate_schedule(spots_s, days_count)

                rows.append({
                    "media": "å®¶æ¨‚ç¦",
                    "region": "å…¨çœè¶…å¸‚",
                    "program_num": int(store_counts_num.get("å®¶æ¨‚ç¦_è¶…å¸‚", 0)),
                    "daypart": daypart_s,
                    "seconds": int(sec),
                    "schedule": sch_s,
                    "spots": sum(sch_s),
                    "rate_display": "è¨ˆé‡è²©",
                    "pkg_display": "è¨ˆé‡è²©",
                    "is_pkg_member": False,
                    "nat_pkg_display": 0,
                })

    # æ’åº
    rows.sort(key=lambda x: (MEDIA_ORDER.get(x["media"], 99), x["seconds"], x["region"]))
    return rows, total_list_accum

# =========================================================
# 5. Bæ–¹æ¡ˆï¼šç”¨æ¨£æ¿ç”¢å‡º Excelï¼ˆä¿ç•™æ‰€æœ‰æ¨£å¼/Logo/æ¡†ç·šï¼‰
# =========================================================
def _remove_merges_in_range(ws, min_row, max_row, min_col, max_col):
    to_remove = []
    for r in list(ws.merged_cells.ranges):
        # merged range bounds
        if (r.min_row <= max_row and r.max_row >= min_row and
            r.min_col <= max_col and r.max_col >= min_col):
            to_remove.append(str(r))
    for addr in to_remove:
        try:
            ws.unmerge_cells(addr)
        except:
            pass

def _clear_values(ws, min_row, max_row, min_col, max_col):
    for r in range(min_row, max_row + 1):
        for c in range(min_col, max_col + 1):
            ws.cell(r, c).value = None

def align_logo_right_to_table(ws, img: XLImage, anchor_row_1based: int, anchor_start_col_1based: int, table_last_col_1based: int):
    """
    è®“åœ–ç‰‡å³å´åˆ‡é½Š table_last_col çš„å³é‚Šç•Œ
    åšæ³•ï¼šä»¥ anchor_start_col ç‚ºèµ·é»ï¼Œè¨ˆç®— (anchor_start_col..table_last_col) çš„åƒç´ å¯¬ï¼Œ
         è¨­ colOff = totalWidth - imgWidth
    """
    # å–å¾—æ¬„å¯¬(px)
    total_px = 0
    for c in range(anchor_start_col_1based, table_last_col_1based + 1):
        letter = get_column_letter(c)
        w = ws.column_dimensions[letter].width
        total_px += col_width_to_pixels(w)

    # openpyxl Image å¯¬é«˜ç‚º px
    img_w = int(img.width)
    offset_px = max(0, total_px - img_w)

    marker = AnchorMarker(
        col=anchor_start_col_1based - 1,
        colOff=px_to_emu(offset_px),
        row=anchor_row_1based - 1,
        rowOff=px_to_emu(0),
    )
    ext = XDRPositiveSize2D(cx=px_to_emu(img_w), cy=px_to_emu(int(img.height)))
    img.anchor = OneCellAnchor(_from=marker, ext=ext)

def generate_excel_from_template(format_type: str,
                                template_path: str,
                                start_dt: date,
                                end_dt: date,
                                client_name: str,
                                product_name: str,
                                rows: list,
                                remarks: list,
                                final_budget_val: int,
                                prod_cost: int,
                                store_counts=None):
    """
    ä¾ format_type å¥—ç”¨å°æ‡‰æ¨£æ¿ã€‚
    å‡è¨­ä½ çš„æ¨£æ¿å·²ç¶“æŠŠï¼š
      - æ¬„å¯¬ã€åˆ—é«˜ã€é¡è‰²ã€æ¡†ç·šã€å­—é«”ã€Logoã€é é¦–é å°¾ç­‰éƒ½è¨­å¥½
    æˆ‘å€‘åªåšï¼š
      1) æ›´æ–°å®¢æˆ¶/èµ°æœŸ/ç”¢å“ç­‰æ–‡å­—
      2) æ›´æ–°æ—¥æœŸæ¬„
      3) æ¸…æ‰èˆŠè³‡æ–™ã€å¡«å…¥æ–° rows
      4) é‡å»º Station åˆä½µã€å…¨çœ package-cost åˆä½µ
      5) è¨­åˆ—å°å€åŸŸ + fitToWidth é¿å… PDF è£åˆ‡
    """
    if not os.path.exists(template_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨£æ¿ï¼š{template_path}ã€‚è«‹æ”¾åœ¨ templates/ å…§ã€‚")

    wb = openpyxl.load_workbook(template_path)
    ws = wb.active  # ä½ ä¹Ÿå¯ä»¥æ”¹æˆæŒ‡å®šåç¨±

    eff_days = (end_dt - start_dt).days + 1
    if eff_days <= 0:
        raise ValueError("æ—¥æœŸå€é–“éŒ¯èª¤ï¼šçµæŸæ—¥å¿…é ˆ >= é–‹å§‹æ—¥")

    # ----- ä¸åŒæ¨£æ¿çš„åº§æ¨™è¨­å®šï¼ˆä¾ä½ ç¾æœ‰ç”Ÿæˆå™¨æ…£ä¾‹ï¼‰-----
    if format_type == "Dongwu":
        # å›ºå®šæ¬„ A-G + æ—¥æœŸå¾ H é–‹å§‹ + æœ€å¾Œæª”æ¬¡æ¬„
        fixed_cols = 7
        day_col_start = 8
        last_col = fixed_cols + eff_days + 1  # spots col
        header_day_row = 7
        header_wk_row = 8
        data_start_row = 9
        pkg_col = 7
        station_col = 1
        # Header cellsï¼ˆæ²¿ç”¨ä½  scratch ç‰ˆæœ¬ä½ç½®ï¼‰
        # A3(å®¢æˆ¶) / A4(Product) / A5(Period) / A6(Medium) ä½ æ¨£æ¿è‹¥ä¸åŒå¯è‡ªè¡Œèª¿æ•´
        ws["B3"].value = client_name
        ws["B4"].value = f"{'ã€'.join([f'{s}ç§’' for s in sorted(set(r['seconds'] for r in rows))])} {product_name}"
        ws["B5"].value = f"{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y. %m. %d')}"
        ws["B6"].value = "/".join(sorted(set(r["media"] for r in rows), key=lambda x: MEDIA_ORDER.get(x, 99)))

    else:
        # Shenghuo / Bolinï¼šå›ºå®šæ¬„ A-E + æ—¥æœŸå¾ F é–‹å§‹ + æœ«ç«¯ æª”æ¬¡/å®šåƒ¹/å°ˆæ¡ˆåƒ¹
        fixed_cols = 5
        day_col_start = 6
        end_c_start = fixed_cols + eff_days + 1  # æª”æ¬¡æ¬„
        last_col = end_c_start + 2  # + å®šåƒ¹ + å°ˆæ¡ˆåƒ¹
        if format_type == "Shenghuo":
            header_day_row = 8  # æ—¥æœŸæ•¸å­—åˆ—
            header_wk_row = None  # ç”Ÿæ´»æ¨£æ¿å¸¸åªæœ‰æ—¥æœŸåˆ—ï¼Œæˆ–ä½ å¯è‡ªè¡Œæ”¹
            data_start_row = 9
        else:  # Bolin
            header_day_row = 6
            header_wk_row = 7
            data_start_row = 8

        station_col = 1
        pkg_col = end_c_start + 2  # å°ˆæ¡ˆåƒ¹æ¬„ï¼ˆä½ åŸæœ¬å°±æ˜¯ç”¨é€™æ¬„ç•¶ package-cost é¡¯ç¤ºï¼‰

        # å¸¸ç”¨æ¬„ä½ï¼ˆä¾ä½  scratch ç‰ˆæœ¬ï¼‰
        # é‰‘éœ–ï¼šB2 client / B4 client / B5 product / å³å´ period/spec åœ¨ç¬¬4åˆ—
        if format_type == "Bolin":
            ws["B2"].value = client_name
            ws["B4"].value = client_name
            ws["B5"].value = product_name
            # Spec + Periodï¼ˆä½ æ¨£æ¿è‹¥æœ‰å›ºå®šåˆä½µæ ¼å°±åªè¦å¯«å…¥å·¦ä¸Šè§’ï¼‰
            sec_str = " ".join([f"{s}ç§’å»£å‘Š" for s in sorted(set(r["seconds"] for r in rows))])
            # é€™å…©æ ¼ä½ç½®éœ€é…åˆä½ çš„é‰‘éœ–æ¨£æ¿ï¼ˆè‹¥ä¸åŒè‡ªè¡Œæ”¹ï¼‰
            ws["F4"].value = f"å»£å‘Šè¦æ ¼ï¼š{sec_str}"
            ws.cell(4, last_col - 1).value = f"åŸ·è¡ŒæœŸé–“ï¼š{start_dt.strftime('%Y.%m.%d')} - {end_dt.strftime('%Y.%m.%d')}"

    # ----- æ—¥æœŸåˆ—å¯«å…¥ï¼ˆç›¡é‡æ²¿ç”¨æ¨£æ¿æ ¼å¼ï¼Œåªå¡«å€¼ï¼‰-----
    weekdays_zh = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    curr = start_dt
    for i in range(eff_days):
        col = day_col_start + i
        d_cell = ws.cell(header_day_row, col)
        d_cell.value = curr.day
        if header_wk_row:
            w_cell = ws.cell(header_wk_row, col)
            w_cell.value = weekdays_zh[curr.weekday()]
        curr += timedelta(days=1)

    # ----- æ¸…æ‰èˆŠè³‡æ–™å€ï¼ˆåªæ¸… valueï¼Œä¸å‹•æ ¼å¼ï¼‰-----
    # é è¨­æ¸… 200 è¡Œï¼Œè¶³å¤ å¤§å¤šæ•¸æƒ…æ³ï¼›ä½ å¯è¦–éœ€è¦èª¿æ•´
    clear_max_row = data_start_row + 200
    _remove_merges_in_range(ws, data_start_row, clear_max_row, 1, last_col)
    _clear_values(ws, data_start_row, clear_max_row, 1, last_col)

    # ----- å¯«å…¥è³‡æ–™ï¼ˆåŒæ¨£åªå¯« valueï¼›æ ¼å¼é æ¨£æ¿åŸæœ¬ cell styleï¼‰-----
    def media_display_name(m):
        if format_type in ["Shenghuo", "Bolin"]:
            # é€™å…©å€‹æ¨£æ¿é€šå¸¸ Station æ¬„å°±æ˜¯ "å…¨å®¶å»£æ’­/æ–°é®®è¦–/å®¶æ¨‚ç¦"
            return m
        # Dongwu çš„ Station æ¬„æœƒé¡¯ç¤ºå…©è¡Œ
        if m == "å…¨å®¶å»£æ’­":
            return "å…¨å®¶ä¾¿åˆ©å•†åº—\né€šè·¯å»£æ’­å»£å‘Š"
        if m == "æ–°é®®è¦–":
            return "å…¨å®¶ä¾¿åˆ©å•†åº—\næ–°é®®è¦–å»£å‘Š"
        return "å®¶æ¨‚ç¦"

    # å¯« rows
    out_row = data_start_row
    # group keyï¼šåŒ media + secondsï¼ˆæ–¹ä¾¿åˆä½µ Station èˆ‡å…¨çœ packageï¼‰
    rows_sorted = sorted(rows, key=lambda x: (MEDIA_ORDER.get(x["media"], 99), x["seconds"], x["region"]))
    groups = []
    for k, g in groupby(rows_sorted, key=lambda x: (x["media"], x["seconds"])):
        groups.append((k, list(g)))

    for (m, sec), g_list in groups:
        group_start = out_row
        for r in g_list:
            # A: Station / B: Region / C: store count / D: daypart / E: spec
            ws.cell(out_row, 1).value = media_display_name(m)
            ws.cell(out_row, 2).value = r["region"]

            # store count
            cnt = r.get("program_num", 0)
            if format_type == "Dongwu":
                ws.cell(out_row, 3).value = cnt
            else:
                suffix = "é¢" if m == "æ–°é®®è¦–" else "åº—"
                ws.cell(out_row, 3).value = f"{int(cnt):,}{suffix}" if isinstance(cnt, (int, float)) else cnt

            ws.cell(out_row, 4).value = r["daypart"]

            # è¦æ ¼æ¬„
            if format_type == "Dongwu":
                ws.cell(out_row, 5).value = f"{r['seconds']}ç§’"
            else:
                if m == "æ–°é®®è¦–":
                    ws.cell(out_row, 5).value = f"{r['seconds']}ç§’\nå½±ç‰‡/å½±åƒ 1920x1080 (mp4)"
                else:
                    ws.cell(out_row, 5).value = f"{r['seconds']}ç§’å»£å‘Š"

            # æ—¥æœŸæ’ç¨‹
            for i, v in enumerate(r["schedule"][:eff_days]):
                ws.cell(out_row, day_col_start + i).value = int(v)

            # æª”æ¬¡ / é‡‘é¡æ¬„
            if format_type == "Dongwu":
                # F: rate(Net) / G: Package-cost(Net)
                # ä½ è¦æ±‚ rate(Net) é¡¯ç¤ºç¸½åƒ¹ â†’ ç›´æ¥å¡« total
                ws.cell(out_row, 6).value = r["rate_display"]

                # å…¨çœï¼šåˆä½µé¡¯ç¤º nat_pkg_displayï¼›åˆ†å€ï¼šé¡¯ç¤ºè‡ªèº« pkg_display
                if r.get("is_pkg_member"):
                    # å…ˆä¸å¡«ï¼ˆå¾Œé¢çµ±ä¸€åˆä½µå¾Œåœ¨ç¬¬ä¸€åˆ—å¡« nat_pkg_displayï¼‰
                    pass
                else:
                    ws.cell(out_row, 7).value = r["pkg_display"]

                # spots æ¬„ï¼ˆæœ€å¾Œä¸€æ¬„ï¼‰
                ws.cell(out_row, last_col).value = int(r["spots"])

            else:
                # æª”æ¬¡æ¬„
                end_c_start = fixed_cols + eff_days + 1
                ws.cell(out_row, end_c_start).value = int(r["spots"])
                # å®šåƒ¹æ¬„ï¼šç”¨ rate_display
                ws.cell(out_row, end_c_start + 1).value = r["rate_display"]
                # å°ˆæ¡ˆåƒ¹æ¬„ï¼šå…¨çœåˆä½µé¡¯ç¤º nat_pkg_displayï¼›åˆ†å€é¡¯ç¤º pkg_display
                if r.get("is_pkg_member"):
                    pass
                else:
                    ws.cell(out_row, end_c_start + 2).value = r["pkg_display"]

            out_row += 1

        group_end = out_row - 1

        # ----- åˆä½µ Station æ¬„ï¼ˆæ•´æ®µ groupï¼‰-----
        if group_end > group_start:
            ws.merge_cells(start_row=group_start, start_column=station_col, end_row=group_end, end_column=station_col)

        # ----- å…¨çœ package-cost åˆä½µ -----
        if g_list and g_list[0].get("is_pkg_member"):
            # package-cost æ¬„ï¼ˆDongwu=Gï¼›Bolin/Shenghuo=å°ˆæ¡ˆåƒ¹ï¼‰
            ws.merge_cells(start_row=group_start, start_column=pkg_col, end_row=group_end, end_column=pkg_col)
            # åœ¨ç¬¬ä¸€åˆ—å¡« nat_pkg_display
            ws.cell(group_start, pkg_col).value = g_list[0].get("nat_pkg_display", 0)

    last_data_row = out_row - 1

    # ----- Remarksï¼ˆå¦‚æœæ¨£æ¿æœ‰å›ºå®šå€å¡Šï¼Œä½ å¯æ”¹æˆå¯«åˆ°æŒ‡å®šä½ç½®ï¼‰-----
    # é€™è£¡ç”¨ã€Œå¯«åœ¨è³‡æ–™å¾Œæ–¹ã€çš„æ–¹å¼ï¼Œé¿å…ç ´å£ä½ æ¨£æ¿æ—¢æœ‰å€å¡Š
    remark_row = last_data_row + 2
    ws.cell(remark_row, 1).value = "Remarksï¼š"
    for i, rm in enumerate(remarks, start=1):
        ws.cell(remark_row + i, 1).value = rm

    # ----- é é¢è¨­å®šï¼šé¿å… PDF å·¦å³è¢«åˆ‡ -----
    ws.page_setup.orientation = ws.ORIENTATION_LANDSCAPE
    ws.page_setup.paperSize = ws.PAPERSIZE_A4
    ws.page_setup.fitToPage = True
    ws.page_setup.fitToWidth = 1
    ws.page_setup.fitToHeight = 0  # è®“é«˜åº¦å¯å»¶ä¼¸ï¼Œé‡é»æ˜¯å¯¬åº¦ä¸è¦è£åˆ‡
    ws.page_margins.left = 0.2
    ws.page_margins.right = 0.2
    ws.page_margins.top = 0.3
    ws.page_margins.bottom = 0.3

    # Print Areaï¼šé–ä½ A1 åˆ°è¡¨æ ¼æœ€å³æ¬„ã€æœ€å¾Œå‚™è¨»åˆ—ï¼ˆæ›´ä¸å®¹æ˜“è¢«è£åˆ‡ï¼‰
    ws.print_area = f"A1:{get_column_letter(last_col)}{remark_row + len(remarks) + 2}"

    # ----- é‰‘éœ– Logo å³å°é½Šï¼ˆBæ–¹æ¡ˆé—œéµä¿®æ­£ï¼‰-----
    if format_type == "Bolin":
        # 1) å…ˆå˜—è©¦æŠ“æ¨£æ¿å…§æ—¢æœ‰åœ–ç‰‡ï¼ˆæœ€ç†æƒ³ï¼šä½ æ¨£æ¿æœ¬ä¾†å°±æœ‰ Logoï¼‰
        img = None
        if hasattr(ws, "_images") and ws._images:
            img = ws._images[0]  # å‡è¨­ç¬¬ä¸€å¼µå°±æ˜¯ Logo
        else:
            # 2) æ²’æœ‰å°±ç”¨ URL ä¸‹è¼‰åŠ ä¸Šå»
            logo_bytes = fetch_logo_bytes(BOLIN_LOGO_URL)
            if logo_bytes:
                img = XLImage(io.BytesIO(logo_bytes))
                ws.add_image(img)

        if img:
            # è®“ Logo çš„å³å´åˆ‡é½Šã€Œè¡¨æ ¼æœ€å³é‚Šç•Œã€
            # æˆ‘å€‘æŠŠ anchor èµ·é»æ”¾åœ¨å€’æ•¸ç¬¬äºŒæ¬„ï¼ˆé€šå¸¸æ˜¯å®šåƒ¹é‚£å€‹å¤§æ¬„ï¼‰ï¼Œå†æŠŠå³é‚Šå°é½Šåˆ° last_col
            anchor_row = 1
            anchor_start_col = max(1, last_col - 1)  # å€’æ•¸ç¬¬äºŒæ¬„
            try:
                align_logo_right_to_table(ws, img, anchor_row, anchor_start_col, last_col)
            except:
                # å³ä¾¿å°é½Šå¤±æ•—ä¹Ÿä¸ä¸­æ–·ï¼ˆè‡³å°‘ä¸æœƒæŠŠæ•´ä»½å ±è¡¨æ”¹å£ï¼‰
                pass

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()

# =========================================================
# 6. Streamlit UI
# =========================================================
def main():
    with st.spinner("æ­£åœ¨è®€å– Google è©¦ç®—è¡¨è¨­å®šæª”..."):
        STORE_COUNTS, STORE_COUNTS_NUM, PRICING_DB, SEC_FACTORS, err = load_config_from_cloud(GSHEET_SHARE_URL)
    if err:
        st.error(f"âŒ è¨­å®šæª”è¼‰å…¥å¤±æ•—: {err}")
        st.stop()

    st.title("ğŸ“º Cue è¡¨ç”Ÿæˆå™¨ï¼ˆBæ–¹æ¡ˆï¼šæ¨£æ¿å¥—ç”¨ï¼Œæ¥µè‡´æ“¬çœŸï¼‰")

    format_type = st.radio("é¸æ“‡æ¨£æ¿æ ¼å¼", ["Dongwu", "Shenghuo", "Bolin"], horizontal=True)
    template_path = TEMPLATE_PATHS[format_type]
    st.caption(f"ä½¿ç”¨æ¨£æ¿ï¼š{template_path}")

    c1, c2, c3, c4 = st.columns(4)
    with c1:
        client_name = st.text_input("å®¢æˆ¶åç¨±", "è¬åœ‹é€šè·¯")
    with c2:
        product_name = st.text_input("ç”¢å“åç¨±", "çµ±ä¸€å¸ƒä¸")
    with c3:
        total_budget_input = st.number_input("ç¸½é ç®— (æœªç¨… Net)", value=1000000, step=10000)
    with c4:
        prod_cost_input = st.number_input("è£½ä½œè²» (æœªç¨…)", value=0, step=1000)

    d1, d2 = st.columns(2)
    with d1:
        start_date = st.date_input("é–‹å§‹æ—¥", date(2026, 1, 1))
    with d2:
        end_date = st.date_input("çµæŸæ—¥", date(2026, 1, 31))
    days_count = (end_date - start_date).days + 1
    if days_count <= 0:
        st.error("æ—¥æœŸå€é–“éŒ¯èª¤ï¼šçµæŸæ—¥å¿…é ˆ >= é–‹å§‹æ—¥")
        st.stop()
    st.info(f"ğŸ“… èµ°æœŸå…± **{days_count}** å¤©")

    with st.expander("ğŸ“ å‚™è¨»æ¬„ä½è¨­å®š", expanded=False):
        rc1, rc2, rc3 = st.columns(3)
        sign_deadline = rc1.date_input("å›ç°½æˆªæ­¢æ—¥", date.today() + timedelta(days=3))
        billing_month = rc2.text_input("è«‹æ¬¾æœˆä»½", "2026å¹´2æœˆ")
        payment_date = rc3.date_input("ä»˜æ¬¾å…Œç¾æ—¥", date(2026, 3, 31))

    st.markdown("### 1) åª’é«”æŠ•æ”¾è¨­å®š")

    colA, colB, colC = st.columns(3)
    config = {}

    with colA:
        st.markdown("#### ğŸ“» å…¨å®¶å»£æ’­")
        rad_on = st.checkbox("å•Ÿç”¨", value=True, key="rad_on")
        if rad_on:
            rad_nat = st.checkbox("å…¨çœè¯æ’­", value=True, key="rad_nat")
            rad_regs = ["å…¨çœ"] if rad_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=REGIONS_ORDER, key="rad_regs")
            if (not rad_nat) and len(rad_regs) == 6:
                rad_nat = True
                rad_regs = ["å…¨çœ"]
                st.info("âœ… å·²é¸æ»¿ 6 å€ï¼Œè‡ªå‹•è¦–ç‚ºå…¨çœè¯æ’­")
            rad_secs = st.multiselect("ç§’æ•¸", DURATIONS, default=[20], key="rad_secs")
            rad_share = st.slider("é ç®—ä½”æ¯”%", 0, 100, 70, key="rad_share")

            sec_shares = {}
            if len(rad_secs) > 1:
                rem = 100
                for i, s in enumerate(sorted(rad_secs)):
                    if i < len(rad_secs) - 1:
                        v = st.slider(f"{s}ç§’ä½”æ¯”", 0, rem, int(rem / 2), key=f"rad_s_{s}")
                        sec_shares[int(s)] = int(v)
                        rem -= v
                    else:
                        sec_shares[int(s)] = int(rem)
            elif rad_secs:
                sec_shares[int(rad_secs[0])] = 100

            config["å…¨å®¶å»£æ’­"] = {
                "is_national": bool(rad_nat),
                "regions": rad_regs,
                "sec_shares": sec_shares,
                "share": int(rad_share),
            }

    with colB:
        st.markdown("#### ğŸ“º æ–°é®®è¦–")
        fv_on = st.checkbox("å•Ÿç”¨", value=True, key="fv_on")
        if fv_on:
            fv_nat = st.checkbox("å…¨çœè¯æ’­ ", value=False, key="fv_nat")
            fv_regs = ["å…¨çœ"] if fv_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=["åŒ—å€", "ä¸­å€"], key="fv_regs")
            if (not fv_nat) and len(fv_regs) == 6:
                fv_nat = True
                fv_regs = ["å…¨çœ"]
                st.info("âœ… å·²é¸æ»¿ 6 å€ï¼Œè‡ªå‹•è¦–ç‚ºå…¨çœè¯æ’­")
            fv_secs = st.multiselect("ç§’æ•¸", DURATIONS, default=[10], key="fv_secs")
            fv_share = st.slider("é ç®—ä½”æ¯”% ", 0, 100, 20, key="fv_share")

            sec_shares = {}
            if len(fv_secs) > 1:
                rem = 100
                for i, s in enumerate(sorted(fv_secs)):
                    if i < len(fv_secs) - 1:
                        v = st.slider(f"{s}ç§’ä½”æ¯” ", 0, rem, int(rem / 2), key=f"fv_s_{s}")
                        sec_shares[int(s)] = int(v)
                        rem -= v
                    else:
                        sec_shares[int(s)] = int(rem)
            elif fv_secs:
                sec_shares[int(fv_secs[0])] = 100

            config["æ–°é®®è¦–"] = {
                "is_national": bool(fv_nat),
                "regions": fv_regs,
                "sec_shares": sec_shares,
                "share": int(fv_share),
            }

    with colC:
        st.markdown("#### ğŸ›’ å®¶æ¨‚ç¦")
        cf_on = st.checkbox("å•Ÿç”¨", value=True, key="cf_on")
        if cf_on:
            cf_secs = st.multiselect("ç§’æ•¸", DURATIONS, default=[20], key="cf_secs")
            cf_share = st.slider("é ç®—ä½”æ¯”%", 0, 100, 10, key="cf_share")

            sec_shares = {}
            if len(cf_secs) > 1:
                rem = 100
                for i, s in enumerate(sorted(cf_secs)):
                    if i < len(cf_secs) - 1:
                        v = st.slider(f"{s}ç§’ä½”æ¯”  ", 0, rem, int(rem / 2), key=f"cf_s_{s}")
                        sec_shares[int(s)] = int(v)
                        rem -= v
                    else:
                        sec_shares[int(s)] = int(rem)
            elif cf_secs:
                sec_shares[int(cf_secs[0])] = 100

            config["å®¶æ¨‚ç¦"] = {
                "is_national": True,
                "regions": ["å…¨çœ"],
                "sec_shares": sec_shares,
                "share": int(cf_share),
            }

    # Normalize shares (optional but recommended)
    if config:
        total_share = sum(v["share"] for v in config.values())
        if total_share != 100 and total_share > 0:
            st.warning(f"ç›®å‰é ç®—ä½”æ¯”åˆè¨ˆ {total_share}%ï¼Œå»ºè­°èª¿æ•´ç‚º 100%ï¼ˆç³»çµ±ä»å¯ç…§æ¯”ä¾‹é‹ç®—ï¼‰")

    st.markdown("### 2) ç”Ÿæˆçµæœ")
    if st.button("ğŸš€ ç”Ÿæˆ Cue è¡¨", type="primary"):
        if not config:
            st.error("è«‹è‡³å°‘å•Ÿç”¨ä¸€å€‹åª’é«”")
            st.stop()

        remarks = get_remarks_text(sign_deadline, billing_month, payment_date)

        with st.spinner("æ­£åœ¨è¨ˆç®—æ’ç¨‹èˆ‡é‡‘é¡..."):
            rows, total_list_accum = calculate_plan_data(
                config=config,
                total_budget=total_budget_input,
                days_count=days_count,
                pricing_db=PRICING_DB,
                sec_factors=SEC_FACTORS,
                store_counts_num=STORE_COUNTS_NUM,
            )

        if not rows:
            st.error("æ²’æœ‰ç”¢å‡ºä»»ä½•åˆ—ï¼ˆè«‹æª¢æŸ¥æ˜¯å¦é ç®—/ç§’æ•¸/å€åŸŸè¨­å®šç‚º 0ï¼‰")
            st.stop()

        with st.spinner("æ­£åœ¨å¥—ç”¨æ¨£æ¿ç”¢å‡º Excelï¼ˆBæ–¹æ¡ˆï¼‰..."):
            try:
                xlsx_bytes = generate_excel_from_template(
                    format_type=format_type,
                    template_path=template_path,
                    start_dt=start_date,
                    end_dt=end_date,
                    client_name=client_name,
                    product_name=product_name,
                    rows=rows,
                    remarks=remarks,
                    final_budget_val=int(total_budget_input),
                    prod_cost=int(prod_cost_input),
                    store_counts=STORE_COUNTS,
                )
            except Exception as e:
                st.error("ç”¢ç”Ÿ Excel å¤±æ•—")
                st.exception(e)
                st.stop()

        st.success("âœ… Excel ç”¢ç”Ÿå®Œæˆï¼ˆBæ–¹æ¡ˆæ¨£æ¿å¥—ç”¨ï¼‰")
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰ Excel",
            data=xlsx_bytes,
            file_name=f"Cue_{safe_filename(client_name)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        # PDF
        st.info("PDF éœ€è¦ LibreOfficeï¼ˆæœ¬æ©Ÿå®‰è£æˆ–é›²ç«¯ packages.txt è£ libreofficeï¼‰")
        with st.spinner("æ­£åœ¨è½‰å‡º PDF..."):
            pdf_bytes, method, err = xlsx_bytes_to_pdf_bytes(xlsx_bytes)
        if pdf_bytes:
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰ PDF",
                data=pdf_bytes,
                file_name=f"Cue_{safe_filename(client_name)}.pdf",
                mime="application/pdf",
            )
        else:
            st.warning(f"PDF ç”Ÿæˆå¤±æ•—ï¼š{err}")

if __name__ == "__main__":
    main()
